import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import yfinance as yf
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

class StockPredictor(nn.Module):
    def __init__(self, input_size=10, hidden_size=128, num_layers=2, dropout=0.3):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
                           batch_first=True, dropout=dropout)
        self.linear = nn.Linear(hidden_size, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.linear(lstm_out[:, -1, :])

def prepare_data(symbol='AAPL', period='10y', seq_length=60):
    data = yf.download(symbol, period=period)

    # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏
    data['Returns'] = data['Close'].pct_change()
    data['EMA_10'] = data['Close'].ewm(span=10).mean()  #span=10  5
    data['EMA_50'] = data['Close'].ewm(span=50).mean()  #span=50  15
    data['Volatility'] = data['Returns'].rolling(20).std()
    data['Volume_EMA'] = data['Volume'].ewm(span=20).mean()

    data = data.dropna()

    features = ['Open', 'High', 'Low', 'Close', 'Volume',
                'Returns', 'EMA_10', 'EMA_50', 'Volatility', 'Volume_EMA']

    # –†–ê–ó–î–ï–õ–Ø–ï–ú –î–ê–ù–ù–´–ï –î–û –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–Ø
    total_size = len(data)
    train_size = int(total_size * 0.7)
    val_size = int(total_size * 0.15)

    train_data = data.iloc[:train_size]
    val_data = data.iloc[train_size:train_size+val_size]
    test_data = data.iloc[train_size+val_size:]

    # –ú–ê–°–®–¢–ê–ë–ò–†–£–ï–ú –ö–ê–ñ–î–´–ô –ù–ê–ë–û–† –û–¢–î–ï–õ–¨–ù–û
    scaler = StandardScaler()
    scaled_train = scaler.fit_transform(train_data[features])
    scaled_val = scaler.transform(val_data[features])
    scaled_test = scaler.transform(test_data[features])

    # –°–û–ó–î–ê–ï–ú –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ò –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ù–ê–ë–û–†–ê
    def create_sequences(scaled_data, dates_data, seq_length):
        X, y, dates = [], [], []
        for i in range(seq_length, len(scaled_data)-1):
            X.append(scaled_data[i-seq_length:i])
            y.append(scaled_data[i+1, 3])  # Close —Ü–µ–Ω—É
            dates.append(dates_data.index[i+1])
        return torch.FloatTensor(np.array(X)), torch.FloatTensor(np.array(y)), dates

    X_train, y_train, dates_train = create_sequences(scaled_train, train_data, seq_length)
    X_val, y_val, dates_val = create_sequences(scaled_val, val_data, seq_length)
    X_test, y_test, dates_test = create_sequences(scaled_test, test_data, seq_length)

    return (X_train, X_val, X_test, y_train, y_val, y_test,
            dates_train, dates_val, dates_test, scaler, data)

def split_data(X, y, dates, train_ratio=0.7, val_ratio=0.15):
    """–†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ 70:15:15"""
    total_size = len(X)
    train_size = int(total_size * train_ratio)
    val_size = int(total_size * val_ratio)

    X_train, X_val, X_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]
    y_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]
    dates_train, dates_val, dates_test = dates[:train_size], dates[train_size:train_size+val_size], dates[train_size+val_size:]

    print(f"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –û–±—É—á–∞—é—â–∏–µ: {len(X_train)} ({len(X_train)/total_size*100:.1f}%)")
    print(f"  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ: {len(X_val)} ({len(X_val)/total_size*100:.1f}%)")
    print(f"  –¢–µ—Å—Ç–æ–≤—ã–µ: {len(X_test)} ({len(X_test)/total_size*100:.1f}%)")

    return (X_train, X_val, X_test, y_train, y_val, y_test, dates_train, dates_val, dates_test)

def train_model(model, X_train, y_train, X_val, y_val, epochs=100):
    """–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –≤—ã–≤–æ–¥–æ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU
    X_train, y_train = X_train.to(device), y_train.to(device)
    X_val, y_val = X_val.to(device), y_val.to(device)

    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    criterion = nn.MSELoss()

    train_losses, val_losses = [], []

    print("\n–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    for epoch in range(epochs):
        # Training
        model.train()
        optimizer.zero_grad()
        outputs = model(X_train)
        loss = criterion(outputs.squeeze(), y_train)
        loss.backward()
        optimizer.step()

        # Validation
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val)
            val_loss = criterion(val_outputs.squeeze(), y_val)

        train_losses.append(loss.item())
        val_losses.append(val_loss.item())

        # –í—ã–≤–æ–¥–∏–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
        print(f'Epoch [{epoch+1:3d}/{epochs}] | Train Loss: {loss.item():.6f} | Val Loss: {val_loss.item():.6f}')

    return train_losses, val_losses

def plot_results(model, X_test, y_test, dates_test, scaler, original_data, features):
    """–°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model.eval()
    with torch.no_grad():
        predictions = model(X_test.to(device)).cpu().numpy()

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞—Å—à—Ç–∞–± –ü–†–ê–í–ò–õ–¨–ù–û
    # –ù—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ Close
    real_prices = []
    pred_prices = []

    for i in range(len(X_test)):
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∫ –æ—Å–Ω–æ–≤—É
        last_sequence = X_test[i][-1:].numpy()  # [1, 10]

        # –ó–∞–º–µ–Ω—è–µ–º Close —Ü–µ–Ω—É –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        last_sequence[0, 3] = predictions[i]  # Close —Ü–µ–Ω–∞

        # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        restored = scaler.inverse_transform(last_sequence)
        pred_prices.append(restored[0, 3])  # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è Close —Ü–µ–Ω–∞

        # –†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ (—É–∂–µ –∑–Ω–∞–µ–º)
        real_seq = X_test[i][-1:].numpy()
        real_seq[0, 3] = y_test[i].item()
        real_restored = scaler.inverse_transform(real_seq)
        real_prices.append(real_restored[0, 3])

    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
    plt.figure(figsize=(15, 8))

    plt.plot(dates_test, real_prices, label='–†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞', linewidth=2, alpha=0.7)
    plt.plot(dates_test, pred_prices, label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ', linewidth=1.5, alpha=0.9)

    plt.title('AAPL: –†–µ–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)', fontsize=14)
    plt.xlabel('–î–∞—Ç–∞')
    plt.ylabel('–¶–µ–Ω–∞ ($)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('test_predictions.png', dpi=300, bbox_inches='tight')
    plt.show()

    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    real_prices = np.array(real_prices)
    pred_prices = np.array(pred_prices)

    mse = np.mean((real_prices - pred_prices) ** 2)
    mape = np.mean(np.abs((real_prices - pred_prices) / real_prices)) * 100

    print(f"\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–• ===")
    print(f"–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE): ${mse:.2f}")
    print(f"–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAPE): {mape:.2f}%")
    print(f"–ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö —Ü–µ–Ω: {real_prices[:5]}")
    print(f"–ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {pred_prices[:5]}")
    print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ 'test_predictions.png'")

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
if __name__ == "__main__":
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ 10 –ª–µ—Ç
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ 70:15:15
    (X_train, X_val, X_test, y_train, y_val, y_test, dates_train, dates_val, dates_test, scaler, data) = prepare_data('AAPL', period='10y')

    print(f"\n–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö X_train: {X_train.shape}")
    print(f"\n–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö X_test: {X_test.shape}")
    print(f"–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {data.index[0].strftime('%Y-%m-%d')} - {data.index[-1].strftime('%Y-%m-%d')}")



    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = StockPredictor(input_size=10, hidden_size=128).to(device)

    # –û–±—É—á–∞–µ–º —Å –≤—ã–≤–æ–¥–æ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
    train_losses, val_losses = train_model(model, X_train, y_train, X_val, y_val, epochs=100)

    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

    features_list = ['Open', 'High', 'Low', 'Close', 'Volume',
                'Returns', 'EMA_10', 'EMA_50', 'Volatility', 'Volume_EMA']

    plot_results(model, X_test, y_test, dates_test, scaler, data, features_list)

    print("\nüéØ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
