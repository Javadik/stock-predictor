# Сравнение CNN+LSTM моделей для предсказания направления движения цен акций

## Обзор моделей

В рамках проекта по улучшению Directional Accuracy (DA) для предсказания акций были разработаны и протестированы 2 версии CNN+LSTM моделей:

1. **Base CNN+LSTM** - полная гибридная архитектура с многошкальным извлечением признаков
2. **Reduced CNN+LSTM** - упрощенная модель с отбором признаков и уменьшенной архитектурой
3. **Extended Reduced CNN+LSTM** - улучшенная версия с расширенным набором признаков (2 → 9 признаков после отбора)

## Архитектурные различия

| Характеристика | Base CNN+LSTM | Reduced CNN+LSTM (оригинальная) | Extended Reduced CNN+LSTM |
|---|---|
| **input_size** | 20 | 2 | 9 (из 22 оригинальных) |
| **CNN channels** | [32, 64, 128, 256] | [16, 32, 64, 128] | [16, 32, 64, 128] |
| **LSTM hidden size** | 256 | 128 | 128 |
| **LSTM layers** | 2 | 2 | 2 |
| **dropout** | 0.3 | 0.3 | 0.3 |
| **Внимание** | LSTM с механизмом внимания | LSTM с механизмом внимания | LSTM с механизмом внимания |
| **Многошкальное извлечение** | Да, 4 разных размера ядер | Да, 4 разных размера ядер | Да, 4 разных размера ядер |
| **Извлечение технических паттернов** | Да (свечные, трендовые, волатильность) | Да (свечные, трендовые, волатильность) | Да (свечные, трендовые, волатильность) |
| **Количество параметров** | ~800K | ~200K | ~1.28M |
| **Общая сложность** | Высокая | Низкая | Средняя |

## Функции потерь

Все модели используют идентичную функцию потерь:

### `CNNLSTMDirectionalLoss`
```python
def __init__(self, mse_weight=0.3, da_weight=0.6, attention_weight=0.05, pattern_weight=0.05):
```
- **MSE потеря** (mse_weight=0.3): Стандартная потеря для точности предсказания цены
- **Направленная потеря** (da_weight=0.6): Основной компонент для Directional Accuracy
- **Регуляризация внимания** (attention_weight=0.05): Для предотвращения перефокусировки
- **Регуляризация паттернов** (pattern_weight=0.05): Для предотвращения переобучения на паттерны

## Параметры обучения

| Параметр | Base CNN+LSTM | Reduced CNN+LSTM (оригинальная) | Extended Reduced CNN+LSTM |
|---|---|
| **Эпохи** | 150 | 50 |
| **Терпение (patience)** | 30 | 15 |
| **Learning Rate** | 0.01 | 0.0005 | 0.0005 |
| **Weight Decay** | 1e-4 | 1e-4 | 1e-4 |
| **Max Norm (clip)** | 0.5 | 0.5 | 0.5 |
| **Scheduler** | ReduceLROnPlateau | ReduceLROnPlateau | ReduceLROnPlateau |
| **Scheduler параметры** | patience=10, factor=0.6 | patience=10, factor=0.6 | patience=10, factor=0.6 |

## Подготовка данных

### Base CNN+LSTM
- Использует 20 технических индикаторов:
  - High, Volume, Returns, EMA_10, EMA_50, Volatility, Volume_EMA
  - RSI, MACD, BB_Position, High_Low_Pct, Price_Change, Volume_Change
  - Momentum, MA_Ratio, Adaptive_Volatility, Trend_Strength, Price_Strength
  - Price_to_VWAP, Volatility_Momentum
- Длина последовательности: 60
- Разделение данных: 70% обучение, 15% валидация, 15% тест

### Reduced CNN+LSTM (оригинальная)
- Использует 2 признака: Diff_High, Diff_Close (разницы в ценах)
- Длина последовательности: 60
- Разделение данных: 65% обучение, 15% валидация, 20% тест

### Extended Reduced CNN+LSTM
- Использует 22 технических индикатора (расширенный набор):
  - High, Volume, Returns, EMA_10, EMA_50, Volatility, Volume_EMA
  - RSI, MACD, BB_Position, High_Low_Pct, Price_Change, Volume_Change
  - Momentum, MA_Ratio, Adaptive_Volatility, Trend_Strength, Price_Strength
  - Price_to_VWAP, Volatility_Momentum, Diff_High, Diff_Close
- После отбора признаков остается 9 признаков:
  - High, Volume, Returns, Volatility, MACD, Volume_Change, MA_Ratio, Adaptive_Volatility, Volatility_Momentum
- Длина последовательности: 60
- Разделение данных: 65% обучение, 15% валидация, 20% тест
- Включает анализ важности признаков и отбор признаков
- Использует FeatureSelector с порогом важности 0.04 и порогом корреляции 0.8

## Архитектурные компоненты

### Base CNN+LSTM
```python
class StockCNNLSTM(nn.Module):
    # Многошкальное извлечение признаков
    self.multiscale_cnn = MultiScaleCNN(input_size, [32, 64, 128, 256])

    # Извлечение технических паттернов
    self.pattern_extractor = TechnicalPatternExtractor(input_size)

    # LSTM с вниманием
    self.attention_lstm = AttentionLSTM(512, 256, 2, 0.3)

    # Выходной слой
    self.classifier = nn.Sequential(...)
```

### Reduced CNN+LSTM (оригинальная и Extended)
```python
class ReducedStockCNNLSTM(nn.Module):
    # Многошкальное извлечение признаков
    self.multiscale_cnn = MultiScaleCNN(input_size, [16, 32, 64, 128])

    # Извлечение технических паттернов
    self.pattern_extractor = TechnicalPatternExtractor(input_size)

    # LSTM с вниманием
    self.attention_lstm = AttentionLSTM(256, 128, 2, 0.3)

    # Выходной слой
    self.classifier = nn.Sequential(...)
```

## Основные компоненты архитектуры

### MultiScaleCNN
- Использует разные размеры ядер (3, 5, 7, 9) для извлечения паттернов разных масштабов
- Применяет двойные свертки для углубления
- Включает BatchNorm и Dropout для стабилизации

### TechnicalPatternExtractor
- Три ветви для извлечения:
 - Свечные паттерны (краткосрочные, ядра 3 и 5)
  - Трендовые паттерны (среднесрочные, ядра 7 и 9)
  - Волатильность (долгосрочные, ядра 11 и 13)
- Адаптивные веса для объединения паттернов

### AttentionLSTM
- Двунаправленный LSTM для захвата прошлого и будущего контекста
- Механизм внимания для фокусировки на важных временных шагах
- Улучшение репрезентации через дополнительные слои

## Результаты тестирования

### Base CNN+LSTM
- **Преимущества**:
  - Более полное использование технических индикаторов
  - Более сложная архитектура для захвата сложных паттернов
  - Более высокая потенциальная точность

- **Недостатки**:
 - Высокая вычислительная сложность
  - Большое количество параметров (~800K)
  - Потенциал переобучения из-за сложности модели

### Reduced CNN+LSTM (оригинальная)
- **Преимущества**:
  - Меньше параметров (~200K)
  - Быстрое обучение инференс
  - Простота модели

- **Недостатки**:
 - Использование только 2 признаков
  - Ограниченная способность захвата сложных паттернов

### Extended Reduced CNN+LSTM
- **Преимущества**:
  - Анализ важности признаков и отбор наиболее значимых
  - Баланс между количеством признаков и сложностью модели
 - Использование 9 наиболее важных признаков из 22
  - Практически 51-52% Directional Accuracy

- **Недостатки**:
 - Нестабильность в предсказаниях (в разных запусках модель может по-разному предсказывать направления)

## Подход к отбору признаков (в Extended Reduced CNN+LSTM)

Extended Reduced CNN+LSTM использует продвинутый подход к отбору признаков:

1. **Анализ важности признаков**:
   - Использует несколько методов (permutation importance, SHAP, correlation analysis)
   - Комбинирует результаты для получения общей важности

2. **Фильтрация признаков**:
   - Удаляет признаки с низкой важностью (< 0.04)
   - Удаляет признаки с высокой корреляцией (> 0.8) для уменьшения избыточности

3. **Обучение на отобранных признаках**:
   - Использует только отобранные признаки для обучения модели
   - Уменьшает размерность входа модели

## Результаты Extended Reduced CNN+LSTM

После запуска модели были получены следующие результаты:

### Запуск 1:
- Directional Accuracy: 52.0% (166 из 319 правильных предсказаний направления)
- Точность для роста: 0.000 (0 из 153 случаев)
- Точность для падения: 1.000 (166 из 166 случаев)

### Запуск 2:
- Directional Accuracy: 51.4% (164 из 319 правильных предсказаний направления)
- Точность для роста: 0.706 (108 из 153 случаев)
- Точность для падения: 0.337 (56 из 166 случаев)

### Запуск 3 (с добавлением шума):
- Directional Accuracy: 52.0% (166 из 319 правильных предсказаний направления)
- Точность для роста: 0.000 (153 случаев)
- Точность для падения: 1.000 (166 случаев)
- Средняя ошибка: $0.02 (все предсказания занижены)
- Процент заниженных предсказаний: 100%

### Отобранные признаки:
1. Volatility_Momentum (важность: 0.516907)
2. Adaptive_Volatility (важность: 0.515626)
3. EMA_50 (важность: 0.515605)
4. High (важность: 0.514331)
5. Price_Strength (важность: 0.514138)
6. MACD (важность: 0.514133)
7. Diff_Close (важность: 0.513976)
8. Volume (важность: 0.513934)
9. BB_Position (важность: 0.513508)

## Проблема дисбаланса

Результаты модели показали нестабильность и сильный дисбаланс в предсказаниях: в разных запусках модель показывает разные результаты, но часто предсказывает только одно направление. В последнем запуске с добавлением шума модель:

1. **Предсказывает только падение** (точность для падения: 1.00, точность для роста: 0.000)
2. **Систематически занижает предсказания** (все 100% предсказаний ниже реальных значений)
3. **Имеет смещенную ошибку** (средняя ошибка $0.02, что указывает на постоянное занижение)

Это указывает на следующие возможные причины:

1. **Систематическая ошибка в обучении**: Модель научилась предсказывать, что цена всегда будет падать или оставаться на том же уровне, но не расти
2. **Дисбаланс в данных**: Возможно, в обучающем наборе преобладают примеры падения
3. **Функция потерь**: Текущая функция потерь может поощрять модель к предсказанию одного направления
4. **Недостаточная регуляризация**: Модель может переобучаться на одном направлении

## Улучшения графиков

В коде была исправлена проблема с разрешением графиков:
- Было: `plt.savefig('cnn_lstm/reduced_cnn_lstm_stock_predictions.png', dpi=30, bbox_inches='tight')`
- Стало: `plt.savefig('cnn_lstm/reduced_cnn_lstm_stock_predictions.png', dpi=300, bbox_inches='tight')`

Теперь графики сохраняются с высоким разрешением 300 dpi, что обеспечивает хорошее качество изображений для публикаций и презентаций.

## Рекомендации по улучшению стабильности

Для улучшения стабильности предсказаний можно рассмотреть следующие подходы:

1. **Фиксация случайного.seed**: Установка фиксированного seed для воспроизводимости результатов
2. **Увеличение количества эпох**: Обучение модели до сходимости
3. **Калибровка модели**: Применение методов калибровки для коррекции предсказаний
4. **Ансамлирование**: Использование нескольких моделей с усреднением предсказаний
5. **Кросс-валидация**: Использование кросс-валидации для оценки стабильности
6. **Балансировка данных**: Использование методов oversampling/undersampling для балансировки классов
7. **Изменение функции потерь**: Использование функций потерь, которые поощряют баланс между направлениями

## Выводы и рекомендации

1. **Архитектурные различия**:
   - Extended Reduced модель использует расширенный набор из 22 признаков, но после отбора остается 9 наиболее важных
   - Это позволяет достичь баланса между сложностью модели и количеством используемых признаков

2. **Подход к обучению**:
   - Extended Reduced модель включает анализ важности признаков и отбор признаков
   - Это позволяет сосредоточиться на наиболее информативных признаках

3. **Компромиссы**:
   - Extended Reduced модель достигает 51-52% Directional Accuracy, что является хорошим результатом
   - Однако наблюдается нестабильность в предсказаниях в разных запусках

4. **Потенциальные улучшения**:
   - Для Extended Reduced модели: улучшение стабильности предсказаний
   - Рассмотреть фиксацию случайного.seed для воспроизводимости
   - Использовать ансамблирование для повышения стабильности
   - Ввести штрафы в функцию потерь для балансировки предсказаний
   - **Критически важно**: Решить проблему систематического занижения предсказаний и дисбаланса между направлениями

5. **Функция потерь**:
   - Все модели используют идентичную специализированную функцию потерь, ориентированную на Directional Accuracy
   - Это позволяет сравнивать модели на равных условиях по отношению к целевой метрике

## Заключение

CNN+LSTM архитектуры предлагают альтернативный подход к задаче предсказания направления движения цен по сравнению с Transformer моделями. Extended Reduced CNN+LSTM показала, что можно достичь 51-52% Directional Accuracy, используя только 9 из 22 наиболее важных признаков, что указывает на эффективность подхода отбора признаков. Модель показала хороший баланс между сложностью и производительностью, достигнув 51-52% точности в определении направления движения цен.

Результаты также выявили проблему нестабильности: в разных запусках модель может по-разному предсказывать направления. Были предприняты попытки решить проблему дисбаланса с помощью:

1. **Добавления шума** - не дал результата, модель по-прежнему предсказывала только падение (точность для падения 1.000, для роста 0.000)
2. **Динамического взвешивания потерь** - веса не изменялись (оставались 1.000 для обоих направлений), модель продолжала предсказывать только падение
3. **Класс-балансированной функции потерь** - также не решила проблему, модель по-прежнему предсказывает только одно направление

В последнем эксперименте с балансировкой по классам модель показала:
- Directional Accuracy: 52.0% (166 из 319 правильных предсказаний направления)
- Точность для роста: 0.000 (153 случая)
- Точность для падения: 1.000 (166 случаев)
- Средняя ошибка: $0.00 (все предсказания занижены)
- Процент заниженных предсказаний: 84.6%

Даже после исправления формулы вычисления эффективных количеств в функции потерь (изменение (1 - β^n) / (1 - β) вместо (1 - β) / (1 - β^n)), модель по-прежнему демонстрирует ту же проблему систематического предсказания только одного направления. Это указывает на более глубокую проблему в архитектуре модели или процессе обучения, которая не решается только изменением функции потерь. Необходимы дополнительные меры, такие как:
- Изменение архитектуры модели
- Аугментация данных
- Калибровка модели
- Использование ансамблей
- Модификация процесса обучения
- Использование аугментации данных для балансировки классов
- Применение методов калибровки предсказаний
- Использование ансамблей моделей с разными подходами к балансировке

В недавнем эксперименте с динамическим взвешиванием потерь была реализована система, которая адаптивно изменяет веса для каждого направления на основе их распространенности в данных. Однако даже эта мера не решила фундаментальную проблему: модель по-прежнему предсказывает только одно направление (падение) с точностью 1.000, хотя веса для роста и падения корректировались (например, Pos: 1.031, Neg: 0.969). Это указывает на то, что проблема может быть связана не только с функцией потерь, но и с самой архитектурой модели или процессом обучения.

Также были улучшены графики - теперь они сохраняются с высоким разрешением 300 dpi, что делает их пригодными для публикаций и презентаций.
