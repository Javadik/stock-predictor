# План сравнения моделей: Transformer vs CNN+LSTM vs текущая LSTM

## Цель сравнения

Определить, какая из трех архитектур (текущая LSTM из stock_predictor_hi.py, Transformer, CNN+LSTM) обеспечивает наилучший показатель Directional Accuracy (DA) на одном и том же датасете акций AAPL.

## Методология сравнения

### 1. Единые условия тестирования
- **Датасет**: Одинаковые данные для всех моделей (AAPL, период 5 лет)
- **Разделение данных**: 70% обучение, 15% валидация, 15% тест
- **Признаки**: Идентичный набор признаков из stock_predictor_hi.py
- **Последовательность**: Длина последовательности 60 дней для всех моделей
- **Метрики**: Directional Accuracy (основная), MSE, MAE, MAPE (дополнительные)

### 2. Фазы эксперимента

#### Фаза 1: Базовое сравнение
- Обучение каждой модели с оптимальными параметрами
- 5 запусков каждой модели для статистической значимости
- Сбор метрик производительности

#### Фаза 2: Анализ устойчивости
- Тестирование на разных временных периодах
- Анализ производительности в периоды высокой волатильности
- Проверка устойчивости к рыночным шокам

#### Фаза 3: Оптимизация гиперпараметров
- Подбор оптимальных гиперпараметров для каждой архитектуры
- Сравнение оптимизированных моделей

## Критерии оценки

### Основные метрики
1. **Directional Accuracy (DA)**
   - Точность предсказания направления движения цены
   - Основной критерий для выбора лучшей модели

2. **Статистическая значимость**
   - T-тест для сравнения средних значений DA
   - Уровень значимости p < 0.05

### Дополнительные метрики
1. **Mean Squared Error (MSE)**
2. **Mean Absolute Error (MAE)**
3. **Mean Absolute Percentage Error (MAPE)**
4. **Время обучения**
5. **Время инференса**
6. **Количество параметров модели**

## Детальное сравнение архитектур

### 1. Текущая LSTM (stock_predictor_hi.py)
**Преимущества:**
- Уже оптимизирована для задачи
- Содержит механизм внимания
- Использует специализированную функцию потерь для DA

**Ожидаемые результаты:**
- DA: 43-59% (текущие показатели)
- Время обучения: среднее
- Интерпретируемость: средняя

### 2. Transformer
**Преимущества:**
- Эффективное улавливание долгосрочных зависимостей
- Параллельная обработка последовательностей
- Многоголовое внимание для анализа различных аспектов

**Ожидаемые результаты:**
- DA: потенциальное улучшение на 5-10%
- Время обучения: выше из-за сложности
- Интерпретируемость: высокая (благодаря механизмам внимания)

### 3. CNN+LSTM
**Преимущества:**
- Эффективное извлечение локальных паттернов
- Иерархическое представление признаков
- Оптимальный баланс между скоростью и точностью

**Ожидаемые результаты:**
- DA: потенциальное улучшение на 3-8%
- Время обучения: среднее
- Интерпретируемость: средняя

## План реализации

### Этап 1: Подготовка (1-2 дня)
1. Создание единой инфраструктуры тестирования
2. Адаптация загрузки и подготовки данных
3. Реализация метрик и процедур оценки

### Этап 2: Базовое тестирование (3-4 дня)
1. Обучение текущей LSTM модели (базовый уровень)
2. Реализация и обучение Transformer модели
3. Реализация и обучение CNN+LSTM модели
4. Сбор и анализ результатов

### Этап 3: Глубокий анализ (2-3 дня)
1. Статистический анализ результатов
2. Визуализация производительности моделей
3. Анализ ошибок и сильных сторон каждой модели

### Этап 4: Оптимизация (2-3 дня)
1. Подбор оптимальных гиперпараметров для лучшей модели
2. Финальное сравнение с базовой LSTM
3. Подготовка рекомендаций

## Структура эксперимента

### 1. Кодовая структура
```
model_comparison/
├── data_loader.py          # Единая загрузка данных
├── models/
│   ├── lstm_model.py       # Текущая LSTM
│   ├── transformer_model.py # Transformer
│   └── cnn_lstm_model.py   # CNN+LSTM
├── training/
│   ├── trainer.py          # Единый тренер
│   └── metrics.py          # Метрики оценки
├── experiments/
│   ├── baseline_test.py    # Базовое сравнение
│   ├── robustness_test.py  # Тест устойчивости
│   └── optimization.py     # Оптимизация
└── results/
    ├── plots/              # Визуализация
    └── analysis.py         # Статистический анализ
```

### 2. Процедура тестирования
```python
def run_comparison_experiment(num_runs=5):
    models = {
        'LSTM': LSTMModel,
        'Transformer': TransformerModel,
        'CNN_LSTM': CNNLSTMModel
    }

    results = {}

    for model_name, model_class in models.items():
        model_results = []

        for run in range(num_runs):
            # Инициализация модели
            model = model_class()

            # Обучение
            train_metrics = train_model(model)

            # Тестирование
            test_metrics = test_model(model)

            model_results.append({
                'train_metrics': train_metrics,
                'test_metrics': test_metrics,
                'model_params': count_parameters(model)
            })

        results[model_name] = model_results

    # Статистический анализ
    statistical_analysis(results)

    return results
```

## Ожидаемые результаты и решения

### Сценарий 1: Transformer показывает лучший DA
- **Решение**: Рекомендовать переход на Transformer архитектуру
- **Дополнительные исследования**: Оптимизация гиперпараметров Transformer

### Сценарий 2: CNN+LSTM показывает лучший DA
- **Решение**: Рекомендовать гибридную архитектуру
- **Дополнительные исследования**: Упрощение архитектуры для ускорения

### Сценарий 3: Текущая LSTM остается лучшей
- **Решение**: Улучшение текущей архитектуры
- **Дополнительные исследования**: Комбинирование с элементами других архитектур

## Критерии принятия решения

### Основной критерий
- **Улучшение DA не менее чем на 5%** по сравнению с текущей LSTM

### Вторичные критерии
- **Статистическая значимость улучшения** (p < 0.05)
- **Умеренное увеличение времени обучения** (не более чем в 2 раза)
- **Сохранение или улучшение других метрик** (MSE, MAE)

### Факторы отклонения
- **Сложность внедрения**: Слишком сложная интеграция
- **Требования к ресурсам**: Чрезмерное увеличение потребления памяти
- **Нестабильность**: Высокая дисперсия результатов между запусками

Этот план обеспечивает всестороннее и объективное сравнение трех архитектур с фокусом на улучшение Directional Accuracy для предсказания акций.
